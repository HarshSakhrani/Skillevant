# -*- coding: utf-8 -*-
"""Phase1.1_ModelBuilding.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16ApyhDtAFZlw7vVUJHsidGE_sSdkr9cC
"""

from google.colab import drive
drive.mount('/content/drive')

#Installing the simpletransformers library
!pip install simpletransformers

#Import essential libraries
import pandas as pd
from simpletransformers.classification import ClassificationModel
from sklearn.model_selection import train_test_split
from simpletransformers.classification import ClassificationModel, ClassificationArgs
from sklearn.metrics import f1_score, accuracy_score

#Read the dataset, consisting of styling and labels (0: Chapter Heading, 1: Heading, 2: Sub-heading,
#               3: Sub Sub Heading, 4: Code,  5: Header/Footer) into dataframe df
df = pd.read_csv("/content/SE_HF&Code.csv")
df.drop(['Unnamed: 0'], axis = 1, inplace = True)
df.head()

#Split dataframe into training set (90%) - X_train, y_train and testing data (10%) - X_test, y_test
X_train, X_test, y_train, y_test = train_test_split(df['text'], df['labels'], test_size=0.1, random_state=100)

#Convert data into dataframes
train_df = pd.DataFrame(list(zip(X_train, y_train)), columns =['text', 'labels']) 
test_df = pd.DataFrame(list(zip(X_test, y_test)), columns =['text', 'labels'])

# Optional model configuration
model_args = ClassificationArgs(num_train_epochs=3)

# Create a ClassificationModel
model = ClassificationModel(
    'bert',
    'bert-base-cased',
    num_labels=6,
    #use_cuda = False,
    args=model_args
)

#Train the model
model.train_model(train_df)

#Define evaluation metrics - f1 score
def f1_multiclass(labels, preds):
    return f1_score(labels, preds, average='micro')
    
result, model_outputs, wrong_predictions = model.eval_model(test_df, f1=f1_multiclass, acc=accuracy_score)

result

!cp -r /content/outputs/checkpoint-4752-epoch-3 "/content/drive/My Drive/Skillevant"

